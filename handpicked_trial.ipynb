{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JBW1b26qflV"
      },
      "outputs": [],
      "source": [
        "#volume and mean crossovers condition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import pandas_datareader.data as web\n",
        "\n",
        "# Download the list of S&P 500 stocks\n",
        "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
        "stocks = sp500.Symbol.to_list()\n",
        "\n",
        "start_date = \"2017-01-01\"\n",
        "end_date = \"2023-01-31\"\n",
        "\n",
        "primary_stocks = []\n",
        "secondary_stocks = []\n",
        "\n",
        "for stock in stocks:\n",
        "    try:\n",
        "        # Get the stock price data from Yahoo Finance\n",
        "        stock_data = yf.download(stock, start=start_date, end=end_date)\n",
        "\n",
        "        # Calculate the 1-year moving average\n",
        "        moving_avg = stock_data[\"Close\"].rolling(window=252).mean()\n",
        "\n",
        "        # Calculate the crossovers\n",
        "        crossover = np.where(stock_data[\"Close\"] > moving_avg, 1, -1)\n",
        "        crossover = np.sign(np.diff(crossover))\n",
        "\n",
        "        # Count the number of positive and negative crossovers\n",
        "        num_positive_crossovers = len(np.where(crossover > 0)[0])\n",
        "        num_negative_crossovers = len(np.where(crossover < 0)[0])\n",
        "\n",
        "        # Determine the trend if the average volume is greater than 1000000\n",
        "        if stock_data[\"Volume\"].mean() > 1000000:\n",
        "            if num_positive_crossovers > num_negative_crossovers:\n",
        "                primary_stocks.append(stock)\n",
        "            else:\n",
        "                secondary_stocks.append(stock)\n",
        "        else:\n",
        "            secondary_stocks.append(stock)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"Primary stocks:\")\n",
        "print(primary_stocks)\n",
        "\n",
        "print(\"Secondary stocks:\")\n",
        "print(secondary_stocks)\n"
      ],
      "metadata": {
        "id": "0A0dqCDEqotD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "primary_stocks"
      ],
      "metadata": {
        "id": "xZdJhRLfqo4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sharpe ratio condition"
      ],
      "metadata": {
        "id": "c_uDvrSrqo6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from tabulate import tabulate\n",
        "\n",
        "def std_dev(stocks, start_date, end_date):\n",
        "    data = yf.download(stocks, start=start_date, end=end_date)['Adj Close']\n",
        "    ret = data.pct_change()\n",
        "    \n",
        "    # Select only the desired stocks\n",
        "    ret = ret[stocks]\n",
        "    \n",
        "    # Calculate the standard deviation of daily percentage changes\n",
        "    std = ret.std() * np.sqrt(252)\n",
        "    results = pd.DataFrame({'Standard Deviation (%)': round(std * 100, 4)})\n",
        "    results.index.name = 'Stock'\n",
        "    return results.sort_values('Standard Deviation (%)', ascending=False)\n",
        "\n",
        "# Define the start and end dates for the analysis\n",
        "start_date = '2017-01-01'\n",
        "end_date = '2022-12-31'\n",
        "\n",
        "# Call the std_dev function for the primary_stocks list and sort the results by standard deviation\n",
        "results = std_dev(primary_stocks, start_date, end_date).sort_values('Standard Deviation (%)', ascending=False)\n",
        "\n",
        "# Split the sorted results into 9 equal sublists based on standard deviation and name the stock lists\n",
        "n = 7\n",
        "chunk_size = len(results) // n\n",
        "stocks_lists = [results.iloc[i:i+chunk_size].index.tolist() for i in range(0, len(results), chunk_size)]\n",
        "for i, stocks in enumerate(stocks_lists):\n",
        "    globals()['stock_list_'+str(i+1)] = stocks\n",
        "\n",
        "# Call the std_dev function for each sublist of stocks and print the results with stock list names\n",
        "for i, stocks in enumerate(stocks_lists):\n",
        "    print(f'Stocks List {i+1}: {globals()[\"stock_list_\"+str(i+1)]}')\n",
        "    results = std_dev(stocks, start_date, end_date)\n",
        "    print(tabulate(results, headers='keys', tablefmt='psql'))\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "GmpWQX64qo9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list_1"
      ],
      "metadata": {
        "id": "TPqlfc5AqpCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "def moving_avg(stock_list):\n",
        "    # Define the start and end dates for the analysis\n",
        "    start_date = '2022-01-01'\n",
        "    end_date = '2022-12-31'\n",
        "\n",
        "    # Download the historical data for the selected stocks\n",
        "    data = yf.download(stock_list, start=start_date, end=end_date)['Adj Close']\n",
        "\n",
        "    # Calculate the moving averages for each stock\n",
        "    moving_avgs = data.rolling(window=20).mean().tail(1).transpose()\n",
        "    moving_avgs = pd.concat([moving_avgs, data.rolling(window=50).mean().tail(1).transpose()], axis=1)\n",
        "    moving_avgs = pd.concat([moving_avgs, data.rolling(window=200).mean().tail(1).transpose()], axis=1)\n",
        "\n",
        "    # Rename the columns\n",
        "    moving_avgs.columns = ['20-day MA', '50-day MA', '200-day MA']\n",
        "\n",
        "    # Get the current price of each stock based on the 'Adj Close' column\n",
        "    current_prices = data.tail(1).transpose()\n",
        "    current_prices.columns = ['Close']\n",
        "\n",
        "    # Create empty lists to store the stocks that are greater than the respective moving averages\n",
        "    new_20_list = []\n",
        "    new_50_list = []\n",
        "    new_200_list = []\n",
        "\n",
        "    # Iterate over each stock\n",
        "    for stock in stock_list:\n",
        "        # Check if the current price is greater than the 20-day moving average\n",
        "        if current_prices.loc[stock, 'Close'] > moving_avgs.loc[stock, '20-day MA']:\n",
        "            new_20_list.append(stock)\n",
        "\n",
        "        # Check if the current price is greater than the 50-day moving average\n",
        "        if current_prices.loc[stock, 'Close'] > moving_avgs.loc[stock, '50-day MA']:\n",
        "            new_50_list.append(stock)\n",
        "\n",
        "        # Check if the current price is greater than the 200-day moving average\n",
        "        if current_prices.loc[stock, 'Close'] > moving_avgs.loc[stock, '200-day MA']:\n",
        "            new_200_list.append(stock)\n",
        "\n",
        "    # Return the stocks that are greater than the respective moving averages\n",
        "    return new_20_list, new_50_list, new_200_list\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "zdhxDkbdq92D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_moving_average = moving_avg(stock_list_7)\n",
        "new_20_list = new_moving_average[0]\n",
        "print(new_20_list)\n",
        "\n",
        "new_50_list = new_moving_average[1]\n",
        "print(new_50_list)\n",
        "\n",
        "new_200_list = new_moving_average[2]\n",
        "print(new_200_list)"
      ],
      "metadata": {
        "id": "UqabzLX_q95b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Define the start and end dates for the analysis\n",
        "start_date = '2017-01-01'\n",
        "end_date = '2022-12-31'\n",
        "\n",
        "# Define the risk-free rate\n",
        "rf_rate = 0.02\n",
        "\n",
        "def calculate_alphas(moving_avg_list):\n",
        "    # Download the historical data for the selected stock list\n",
        "    data = yf.download(moving_avg_list, start=start_date, end=end_date)['Adj Close']\n",
        "\n",
        "    # Calculate the daily returns for each stock\n",
        "    returns = data.pct_change().dropna()\n",
        "\n",
        "    # Download the historical data for the market index (e.g., S&P 500)\n",
        "    market = yf.download('^GSPC', start=start_date, end=end_date)['Adj Close']\n",
        "    market_returns = market.pct_change().dropna()\n",
        "\n",
        "    # Calculate the beta and alpha for each stock\n",
        "    alphas = {}\n",
        "    for stock in returns.columns:\n",
        "        cov = returns[stock].cov(market_returns)\n",
        "        var = market_returns.var()\n",
        "        beta = cov / var\n",
        "        rf_adjusted = (1 + rf_rate) ** (1/365) - 1\n",
        "        alpha = returns[stock].mean() - rf_adjusted - beta * (market_returns.mean() - rf_adjusted)\n",
        "        alphas[stock] = alpha\n",
        "\n",
        "    # Sort the stocks by alpha in descending order\n",
        "    results = pd.Series(alphas).sort_values(ascending=False)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Stocks sorted by alpha for \" + str(moving_avg_list) + \":\")\n",
        "    print(results)"
      ],
      "metadata": {
        "id": "KYV6t0QDsKXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_alphas(new_200_list)"
      ],
      "metadata": {
        "id": "Hx-tct_LsKad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}